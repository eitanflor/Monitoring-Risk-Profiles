{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import GoogleV3\n",
    "from shapely.geometry import Point\n",
    "from shapely import wkt\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bs4 as bs\n",
    "import warnings\n",
    "import requests \n",
    "import pandasql\n",
    "import pyodbc\n",
    "import random\n",
    "import gmplot \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.doogal.co.uk/polylines.php\n",
    "polylines_df = pd.read_csv('polylines.csv')\n",
    "polylines_list = polylines_df.values.tolist()\n",
    "polylines_string = json.dumps(polylines_list).replace(\",\", \"\").replace(\"]]\", \"\").replace(\"[\", \"\").replace(\"]\", \",\")\n",
    "\n",
    "multipolygon_df = pd.DataFrame({'geom': ['MULTIPOLYGON ((('+polylines_string+')))']})\n",
    "multipolygon_df['geom'] = multipolygon_df['geom'].apply(wkt.loads)\n",
    "multipolygon = multipolygon_df.iloc[0]['geom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(number, polygon):\n",
    "    points = []\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    while len(points) < number:\n",
    "        #Florida International University Latitude\n",
    "        x = np.random.normal(25.7574, 0.20, 1)\n",
    "        #Florida International University Longitude\n",
    "        y = np.random.normal(-80.3733, 0.15, 1)\n",
    "        pt = x, y\n",
    "        pnt = Point(pt)\n",
    "        if polygon.contains(pnt):\n",
    "            points.append(pt)\n",
    "    return(points)\n",
    "\n",
    "# calls function to generate a specified number of (Latitude, Longitude) coordinates bounded by polygon  \n",
    "coordinates = generate_random(20000, multipolygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save coordinate data to csv\n",
    "df = pd.DataFrame(coordinates)\n",
    "\n",
    "df.to_csv(\"coordinates.csv\", sep = ',', index = False, header = ['Latitude', 'Longitude'])\n",
    "\n",
    "# Read and Load Data\n",
    "data = pd.read_csv('coordinates.csv', sep = ',') \n",
    "\n",
    "# Formatting of Dataframe (remove [] and string -> float)\n",
    "data['Latitude'] = data['Latitude'].str.strip('[]').astype(float)\n",
    "data['Longitude'] = data['Longitude'].str.strip('[]').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Central Location (FIU MMC CAMPUS)\n",
    "gmap = gmplot.GoogleMapPlotter(25.7574, -80.3733, 15)\n",
    "gmap.marker(25.7574, -80.3733, color = 'red')\n",
    "\n",
    "# Loop over and Mark Lattitude and Longitude Coordinates in Map\n",
    "for latitude, longitude in data.itertuples(index = False):\n",
    "     gmap.marker(latitude, longitude, color = 'cornflowerblue')\n",
    "\n",
    "# Google API Key\n",
    "googlekey = \"AIzaSyB8Qm6takzPBAxsfqUXclRf5Bc81ZDLuuU\"        \n",
    "        \n",
    "# Google API Key    \n",
    "gmap.apikey = googlekey\n",
    "\n",
    "# Save Generated Map to a Given Directory \n",
    "gmap.draw('map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = GoogleV3(api_key = googlekey)\n",
    "\n",
    "# Converts coordinates to nearest address calling Google's Geocode API\n",
    "addresses = []\n",
    "for i in range(len(coordinates)):\n",
    "    location = geolocator.reverse(coordinates[i])\n",
    "    string = json.dumps(location.raw)\n",
    "    jsondata = json.loads(string)\n",
    "    addresses.append(jsondata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters the different locations\n",
    "filter_types = []\n",
    "\n",
    "for i in range(len(addresses)):\n",
    "    if addresses[i]['types'][0] in ['street_address', 'premise']:\n",
    "        filter_types.append(addresses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses the json structure to format \n",
    "formatted_data = []\n",
    "\n",
    "for i in range(len(filter_types)):\n",
    "    formatting = {\n",
    "                'place_id': filter_types[i]['place_id'],\n",
    "                'formatted_address': filter_types[i]['formatted_address'],\n",
    "                'latitude': filter_types[i]['geometry']['location']['lat'],\n",
    "                'longitude': filter_types[i]['geometry']['location']['lng']\n",
    "                 }\n",
    "    formatted_data.append(formatting)\n",
    "\n",
    "df = pd.DataFrame(formatted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block eliminates duplicate addresses\n",
    "placeid_list = []\n",
    "for i in range(len(filter_types)):\n",
    "    placeid_list.append(filter_types[i]['place_id'])\n",
    "    \n",
    "unique_list = [] \n",
    "for i in placeid_list:   \n",
    "    if i not in unique_list: \n",
    "        unique_list.append(i) \n",
    "\n",
    "unique_df = pd.DataFrame(unique_list)\n",
    "unique_df.rename(columns={0:'place_id'}, inplace = True)\n",
    "\n",
    "df = pd.concat([df, unique_df], axis=1, join='inner')\n",
    "df = df.iloc[:, : 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scrape current values and demographics for FIU \n",
    "source = urllib.request.urlopen('https://www.collegetuitioncompare.com/edu/133951/florida-international-university/enrollment/').read()\n",
    "soup = bs.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "table = soup.table\n",
    "table_rows = table.find_all('tr')\n",
    "\n",
    "total = int((table_rows[1].find_all('td')[0].text).replace(\",\", \"\"))\n",
    "women = int((table_rows[3].find_all('td')[0].text).replace(\",\", \"\"))\n",
    "\n",
    "frac_women = women / total\n",
    "# This split handles the women\n",
    "first_split = df.sample(frac = frac_women, random_state = 200)\n",
    "\n",
    "# This split handles the remaining (men)\n",
    "second_split = df.drop(first_split.index)\n",
    "\n",
    "# Assign genders based on proportion\n",
    "first_split['gender'] = 'F'\n",
    "second_split['gender'] = 'M'\n",
    "\n",
    "df = first_split.append(second_split, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index as column to dataframe (mimic of a student id)\n",
    "df['sid'] = df.index\n",
    "\n",
    "# hypothesized parameters\n",
    "frac_student = 0.55\n",
    "frac_faculty = 0.05\n",
    "frac_support = 0.50\n",
    "\n",
    "first_split_student = df.sample(frac = frac_student, random_state = 200)\n",
    "second_split_faculty = df.drop(first_split_student.index).sample(frac = frac_faculty, random_state = 200)\n",
    "third_split_support = df.drop(first_split_student.index).drop(second_split_faculty.index).sample(frac = frac_support, random_state = 200)\n",
    "fourth_split_admin = df.drop(first_split_student.index).drop(second_split_faculty.index).drop(third_split_support.index)\n",
    "\n",
    "# Define split with values\n",
    "first_split_student['classification'] = 'Student'\n",
    "second_split_faculty['classification'] = 'Faculty'\n",
    "third_split_support['classification'] = 'Support'\n",
    "fourth_split_admin['classification'] = 'Administrative'\n",
    "\n",
    "# combine dataframe\n",
    "df = first_split_student.append([second_split_faculty,third_split_support,fourth_split_admin],sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of hypothesized proportions\n",
    "print('Student Proportion: {}'.format(round((len(df.loc[df['classification'] == 'Student']) / len(df)), 2))),\n",
    "print('Faculty Proportion: {}'.format(round((len(df.loc[df['classification'] == 'Faculty']) / len(df)), 2))),\n",
    "print('Support Proportion: {}'.format(round((len(df.loc[df['classification'] == 'Support']) / len(df)), 2))),\n",
    "print('Administrative Proportion: {}'.format(round((len(df.loc[df['classification'] == 'Administrative']) / len(df)), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress FutureDeprecation Warning (coming from helper function blocks.py in lib of pandas)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Repeating ID's indicates household size\n",
    "filtered = pd.DataFrame(df.groupby('place_id').filter(lambda g: len(g) > 1).groupby('place_id').size().sort_values(ascending=False))\n",
    "filtered.columns = ['count']\n",
    "filtered = filtered.reset_index()\n",
    "\n",
    "# add household to revised_df and initialize to 0\n",
    "df['household'] = 0\n",
    "\n",
    "for index in range(len(filtered)):\n",
    "    df.iloc[[df['place_id'] == filtered.iloc[index]['place_id']], [7]] = filtered.iloc[index]['count']        \n",
    "\n",
    "# Remainder will be between [1, 4]\n",
    "for index in range(len(df)):\n",
    "    if df.iloc[index]['household'] == 0:\n",
    "        df.iloc[[index], [7]] = random.randint(1, 4)\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate/create age column\n",
    "df['age'] = 0    \n",
    "\n",
    "# students ages between [18, 25] \n",
    "# all others ages between [35, 60] \n",
    "\n",
    "for index in range(len(df)):\n",
    "    # the 80% of students\n",
    "    if df.loc[df.index[index]]['classification'] == 'Student':\n",
    "        df.iloc[[index], [8]] = random.randint(18, 25)\n",
    "    \n",
    "    # everyone else (faculty, support, admin)       \n",
    "    elif df.loc[df.index[index]]['classification'] == 'Faculty':\n",
    "        df.iloc[[index], [8]] = random.randint(35, 60) \n",
    "    \n",
    "    elif df.loc[df.index[index]]['classification'] == 'Support':\n",
    "        df.iloc[[index], [8]] = random.randint(35, 60)     \n",
    "    \n",
    "    elif df.loc[df.index[index]]['classification'] == 'Administrative':\n",
    "        df.iloc[[index], [8]] = random.randint(35, 60)   \n",
    "    \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Zip Codes from Full Address\n",
    "zipcodes = [i[-1] for i in df.formatted_address.str.split('FL ')]\n",
    "for i in range(len(zipcodes)):\n",
    "    zipcodes[i] = zipcodes[i].split(\",\")[0]\n",
    "    \n",
    "zipcodes = pd.DataFrame(zipcodes)\n",
    "zipcodes.columns = ['zipcode']\n",
    "\n",
    "\n",
    "\n",
    "# reset index and preserve structure\n",
    "copy = df.reset_index().drop(['index'], axis=1)\n",
    "# Append to full dataframe\n",
    "df = pd.concat([copy, zipcodes], axis=1)\n",
    "\n",
    "df = df[df['zipcode'] != 'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv of gender names to assign\n",
    "url = 'https://raw.githubusercontent.com/hadley/data-baby-names/master/baby-names.csv'\n",
    "namesdf = pd.read_csv(url, error_bad_lines=False)\n",
    "namesdf= namesdf[['name', 'sex']]\n",
    "\n",
    "# replaces boy/firl to M/F\n",
    "namesdf['sex'].replace('boy', 'M',inplace=True)\n",
    "namesdf['sex'].replace('girl', 'F',inplace=True)\n",
    "\n",
    "# Counts the existing genders that we fabricated \n",
    "gender_frequency = df['gender'].value_counts()\n",
    "\n",
    "# Splits gender frequency in fabrication\n",
    "female_freq= gender_frequency[0]\n",
    "male_freq= gender_frequency[1]\n",
    "\n",
    "# Excludes name that exceed the quantity of gender in fabrication\n",
    "male_name = namesdf[namesdf.sex.isin(['M'])].head(male_freq)\n",
    "female_name = namesdf[namesdf.sex.isin(['F'])].head(female_freq)\n",
    "\n",
    "#Combines with names\n",
    "frames = [male_name,female_name]\n",
    "combine_frames = pd.concat(frames)\n",
    "\n",
    "combine_names=combine_frames.sort_values(by=['sex']).reset_index(drop=True)\n",
    "combine_names= combine_names[['name']]\n",
    "\n",
    "#Sorts by gender\n",
    "df=df.sort_values(by=['gender']).reset_index(drop=True)\n",
    "\n",
    "#Combines with names with frabicated dataframe\n",
    "df = pd.concat([df, combine_names], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'localhost'\n",
    "database = 'Datathon'\n",
    "username = 'Datathon'\n",
    "password = 'Datathon'\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+password)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "sqldf = pd.read_sql_query(\n",
    "'''\n",
    "SELECT [Academic_Year]\n",
    "      ,[Semester]\n",
    "      ,[Reference_Number]\n",
    "      ,[Course]\n",
    "      ,[Section]\n",
    "      ,[Course_Name]\n",
    "      ,[Department]\n",
    "      ,[Day]\n",
    "      ,[Credit]\n",
    "      ,[Start_Date]\n",
    "      ,[End_Date]\n",
    "      ,[Time]\n",
    "      ,TRY_CONVERT(INT,[Enrollment]) AS 'Enrollment'\n",
    "      ,[Subject]\n",
    "      ,TRY_CONVERT(INT,[Level]) AS 'Level'\n",
    "      ,[Capacity]\n",
    "      ,[Campus]\n",
    "      ,[Facility]\n",
    "  FROM [dbo].[Scheduling_Capacity]\n",
    "  WHERE TRY_CONVERT(INT,[Level]) < 5000\n",
    "  ORDER BY Course\n",
    "''', cnxn)\n",
    "\n",
    "classes = sqldf.values.tolist()\n",
    "\n",
    "studentdf = df.loc[df['classification'] == 'Student'].sort_values(by=['sid'])\n",
    "students = studentdf.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_matrix =[]\n",
    "\n",
    "pos = 0\n",
    "for i in range(len(classes)):\n",
    "    for j in range(classes[i][12]):\n",
    "        #Student -Register for-> Classes\n",
    "        register =[students[pos][5], classes[i][2]]\n",
    "        enrollment_matrix.append(register)\n",
    "        pos = pos + 1\n",
    "        if pos >= len(students):\n",
    "            pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facultydf = df.loc[df['classification'] == 'Faculty'].sort_values(by=['sid'])\n",
    "faculty = facultydf.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructor_matrix=[]\n",
    "\n",
    "pos = 0\n",
    "for i in range(len(classes)):\n",
    "    #Classes -Taught by-> Teachers\n",
    "    instruct = [classes[i][2],faculty[pos][5]]\n",
    "    instructor_matrix.append(instruct)\n",
    "    pos = pos + 1\n",
    "    if pos >= len(faculty):\n",
    "        pos = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_matrix = df[['sid','zipcode']].values.tolist()\n",
    "    \n",
    "enrollment_matrix_df = pd.DataFrame(enrollment_matrix, columns=['sid','Reference_Number'])\n",
    "\n",
    "instructor_matrix_df = pd.DataFrame(instructor_matrix, columns=['Reference_Number','sid'])\n",
    "\n",
    "zipcode_matrix_df=pd.DataFrame(zipcode_matrix, columns=['Link','ToNode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://services1.arcgis.com/CY1LXxl9zlJeBuRZ/arcgis/rest/services/Florida_Cases_Zips_COVID19/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json') \n",
    "json_data = response.json()\n",
    "\n",
    "zipcode_data = []\n",
    "for i in range(len(json_data['features'])):\n",
    "    zipcode = json_data['features'][i]['attributes']['ZIP']\n",
    "    cases = json_data['features'][i]['attributes']['Cases_1']\n",
    "    zip_data = [zipcode, cases]\n",
    "    zipcode_data.append(zip_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodedf =  pd.DataFrame(zipcode_data, columns=['zipcode','cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.DataFrame(pandasql.sqldf('''   \n",
    "                            SELECT name, sid, zipcode, household, age,  gender, formatted_address AS 'address'\n",
    "                            FROM df\n",
    "                            WHERE classification = 'Student'\n",
    "                            ''', locals()))\n",
    "\n",
    "faculty = pd.DataFrame(pandasql.sqldf('''   \n",
    "                            SELECT name, sid, zipcode, household, age,  gender, formatted_address AS 'address'\n",
    "                            FROM df\n",
    "                            WHERE classification = 'Faculty'\n",
    "                            ''', locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodedf.to_csv(\"Data/zipcode.csv\", index=False)\n",
    "sqldf.to_csv(\"Data/courses.csv\",index=False)\n",
    "enrollment_matrix_df.to_csv(\"Data/enroll.csv\", index=False)\n",
    "instructor_matrix_df.to_csv(\"Data/instruct.csv\", index=False)\n",
    "students.to_csv(\"Data/students.csv\", index=False)\n",
    "faculty.to_csv(\"Data/faculty.csv\", index=False)\n",
    "df.to_csv(\"Data/people.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
